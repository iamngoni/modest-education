#### Question 1

a. Show the following properties of the sigmoid and tanh activation functions denoted by $\phi(v)$ in this case:

i. Sigmoid Activation: $\phi(-v) = 1 - \phi(v)$

ii. Tahn Activation: $\phi(-v) = -\phi(v)$

iii. Hard Tahn Activation: $\phi(-v) = -\phi(v)$

b. You are a Data Scientist for a local bank. You are required to design classifier that can predict whether a customer qualifies for a bank loan or not using any appropriate neural network. Use your discretion to come up with features (details provided by the applicant) you see fit for the system. Illustrate your answer with any appropriate neural network carry out the task.

#### Question 2

a. Briefly explain any four types of Activation functions used in Neural Networks.

b. Neural networks require lots of data to be trained properly. If you have too little data (too few input-target pairs) the first thing to try is to get more. However, sometimes this is simply not possible and, then, to split up the few data you have in a training set and a test set might be considered wasteful. Describe how K-fold cross validation can be used to deal with this problem.

c. With a supervised learning algorithm, we can specify target output values, but we may never get close to those targets at the end of learning. Give two reasons why this might happen.

#### Question 3

a. Consider an activation volume of size `13x13x64` and a filter size of `3x3x64`. Discuss whether it is possible to perform convolutions with strides 2, 3,4 and 5. Justify your answer in each case.

b. Bob divided the labeled classification data into a portion used for model construction and another portion for validation. Bob then tested 1000 neural architectures by learning parameters (backpropagating) on the model-construction portition and testing its accuracy on the validation proportion.

    i. Discuss why the resulting model is likely to yield poorer accuracy on the out-of-sample test data as compared to the validation data, even though the validation data was not used for learning parameters.

    ii. What are you recommendations for Bob on using the results of his 1000 validations?

c. Suppose thaat you have a model that provides around `80%` accuracy on the training as well as on the on the out-of-sample test data. Would you recommend increasing the amount of data or adjusting the model to improve accuracy? Justify your answer.

#### Question 4

a. Perform a `4x4` pooling at stride 1 of the input volume in the upper-left corner of Figure 1 below:

![Figure 1](./images/1.png)

b. Discuss the effect of increasing the regularizaation parameter on the training and testing accuracy. Highlight the point at which training and testing accuracy become similar.

c. The Back-Propagation learning algorithm for training feed-forward neural networks requires the activation and error functions to be differentiable. Explain what that means and why it is true.

#### Question 5

Explain the architecture for each of the following Neural Networks describing the problem for which it is best suited:

a. Radial Basis Function Networks (RBF)

b. Self-Organizing Map (SOM)

c. Restricted Boltzman Machine (RBM)

d. The Perceptron

e. A Multilayer Feedforward Network
